# web_crawler

 - root_url for starting point  
 - number of thread to be opened  
 - output.txt for visited urls  

Set data structure for visited urls(visited_urls)  
Queue data structure for urls to be visited(url_list)  
  
## Feature  
 - Multithread option with desired thread numbers  
 - Fail handling for unresponsive urls and connection error  
 - Logging for each error type
 - Units tests

## to do  
 - proper tests  
 - Distributed architecture  
 - Extensive error handling  
 - Dynamic throttling algorithm 
  

